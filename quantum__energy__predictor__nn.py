# -*- coding: utf-8 -*-
"""QUANTUM _ENERGY _PREDICTOR _NN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lLMf96WSreGaWQwAGiAsr5IvtsQz-J_7
"""

import numpy as np
import matplotlib.pyplot as plt

# ℏ = 1, Energy levels: E_n = (n + 0.5) * ω
omegas = np.linspace(0.1, 5.0, 200)  # frequencies
n_levels = 5  # energy levels n = 0 to 4

# Build dataset: For each omega, calculate E0 to E4
X = []
y = []

for omega in omegas:
    for n in range(n_levels):
        X.append([omega, n])  # input: frequency & energy level index
        E_n = (n + 0.5) * omega
        noise = np.random.normal(0, 0.05)  # small noise
        y.append(E_n + noise)

X = np.array(X)
y = np.array(y)

print(f"Input shape: {X.shape}, Output shape: {y.shape}")

# Optional: visualize
plt.scatter(X[:,0], y, s=5, alpha=0.6)
plt.xlabel("Frequency ω")
plt.ylabel("Energy Eₙ")
plt.title("Generated Quantum Energy Levels (with noise)")
plt.grid(True)
plt.show()

import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Scale inputs (omega and n)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Build the neural network model
model = keras.Sequential([
    keras.layers.Dense(32, activation='relu', input_shape=(2,)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1)  # Output: predicted energy
])

# Compile the model with optimizer and loss function
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the model for 100 epochs
history = model.fit(X_train, y_train, epochs=100, batch_size=16,
                    validation_data=(X_test, y_test), verbose=1)

# Plot training and validation loss curves
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.title('Training Performance')
plt.legend()
plt.grid(True)
plt.show()



# Predict on the test set
y_pred = model.predict(X_test).flatten()  # Flatten to match shape

# Print first 5 predictions vs actual values
for i in range(5):
    print(f"ω: {X_test[i][0]:.2f}, n: {X_test[i][1]:.0f} → Predicted Eₙ: {y_pred[i]:.3f}, Actual Eₙ: {y_test[i]:.3f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
plt.scatter(y_test, y_pred, alpha=0.6, s=10, color='blue')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label="Perfect Prediction")
plt.xlabel('Actual Energy (Eₙ)')
plt.ylabel('Predicted Energy')
plt.title('Model Predictions vs Actual Values')
plt.legend()
plt.grid(True)
plt.show()

# Save the trained model in HDF5 format
model.save("quantum_energy_predictor_model.h5")
print("Model saved successfully!")

from google.colab import files
files.download("quantum_energy_predictor_model.h5")

plt.figure(figsize=(8,5))
plt.scatter(y_test, y_pred, alpha=0.6, s=10, color='blue')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label="Perfect Prediction")
plt.xlabel('Actual Energy (Eₙ)')
plt.ylabel('Predicted Energy')
plt.title('Model Predictions vs Actual Values')
plt.legend()
plt.grid(True)

# Save plot as PNG
plt.savefig("prediction_plot.png")
files.download("prediction_plot.png")